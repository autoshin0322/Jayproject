import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix

# === ê¸°ë³¸ ì„¤ì • ===
path = "test"  # í´ë” ê²½ë¡œ
true_df = pd.read_csv(f"{path}/annotation.csv")
pred_df = pd.read_csv(f"{path}/output/input.mp4_segments.csv")

# === FPS ì„¤ì • ===
FPS = 32
timestep = 1 / FPS

# === ì‚¬ìš©ì ì§€ì • ì‹œê°„ ë²”ìœ„ (ì´ˆ ë‹¨ìœ„) ===
START_TIME = 608 # ë¶„ì„ ì‹œì‘ ì‹œì  (ì˜ˆ: 600ì´ˆ)
END_TIME = 1472    # ë¶„ì„ ì¢…ë£Œ ì‹œì  (ì˜ˆ: 1200ì´ˆ)

# === â±ï¸ ì‹œê°„ ë³´ì •: input.mp4_segments.csv â†’ ì „ì—­ íƒ€ì„ë¼ì¸ìœ¼ë¡œ shift ===
pred_df["start_time"] = pred_df["start_time"] + START_TIME
pred_df["end_time"] = pred_df["end_time"] + START_TIME

# === ì „ì²´ ì‹œê°„ êµ¬ê°„ ìƒì„± (ì§€ì •ëœ êµ¬ê°„ë§Œ í‰ê°€) ===
timeline = np.arange(START_TIME, END_TIME, timestep)

# === Ground Truth / Prediction ì´ˆê¸°í™” ===
y_true = np.zeros(len(timeline))
y_pred = np.zeros(len(timeline))

# === Ground Truth: ì‚¬ëŒì´ ì§€ì •í•œ êµ¬ê°„ ===
for _, row in true_df.iterrows():
    start, end = row["start_time"], row["end_time"]
    # ì§€ì •ëœ ì‹œê°„ ë²”ìœ„ì™€ ê²¹ì¹˜ëŠ” êµ¬ê°„ë§Œ ë°˜ì˜
    if end < START_TIME or start > END_TIME:
        continue
    mask = (timeline >= start) & (timeline <= end)
    y_true[mask] = 1

# === Model Prediction: ëª¨ë¸ì´ ê°ì§€í•œ êµ¬ê°„ ===
for _, row in pred_df.iterrows():
    start, end = row["start_time"], row["end_time"]
    if end < START_TIME or start > END_TIME:
        continue
    mask = (timeline >= start) & (timeline <= end)
    y_pred[mask] = 1

# === ì„±ëŠ¥ í‰ê°€ ===
precision = precision_score(y_true, y_pred, zero_division=0)
recall = recall_score(y_true, y_pred, zero_division=0)
f1 = f1_score(y_true, y_pred, zero_division=0)
accuracy = accuracy_score(y_true, y_pred)

print(f"â± í‰ê°€ êµ¬ê°„: {START_TIME:.1f}s ~ {END_TIME:.1f}s")
print(f"Precision: {precision:.4f}")
print(f"Recall:    {recall:.4f}")
print(f"F1-score:  {f1:.4f}")
print(f"Accuracy:  {accuracy:.4f}")

# === Confusion Matrix ê³„ì‚° ===
cm = confusion_matrix(y_true, y_pred)
cm_df = pd.DataFrame(
    cm,
    index=["True_NoGesture", "True_Gesture"],
    columns=["Pred_NoGesture", "Pred_Gesture"]
)

# === Confusion Matrix ì‹œê°í™” ===
plt.figure(figsize=(5, 4))
sns.heatmap(cm_df, annot=True, fmt='d', cmap="Blues")
plt.title(f"Confusion Matrix ({START_TIME}-{END_TIME}s)")
plt.ylabel("True Label")
plt.xlabel("Predicted Label")
plt.tight_layout()
plt.savefig(f"{path}/output/confusion_matrix.png", dpi=300)
plt.close()
print(f"ğŸ–¼ï¸ Confusion Matrix gespeichert: {path}/output/confusion_matrix.png")

# === í”„ë ˆì„ ë‹¨ìœ„ ë¹„êµ CSV ìƒì„± ===
comparison_df = pd.DataFrame({
    "time(sec)": timeline,
    "Ground Truth": y_true.astype(int),
    "Prediction": y_pred.astype(int)
})
comparison_path = f"{path}/output/groundtruth_vs_prediction.csv"
comparison_df.to_csv(comparison_path, index=False)
print(f"ğŸ“„ Vergleich CSV gespeichert: {comparison_path}")

# === í‰ê°€ ê²°ê³¼ ì €ì¥ ===
pd.DataFrame({
    "metric": ["precision", "recall", "f1", "accuracy"],
    "value": [precision, recall, f1, accuracy]
}).to_csv(f"{path}/output/evaluation.csv", index=False)
print(f"âœ… Ergebnisse gespeichert in {path}/output/evaluation.csv")