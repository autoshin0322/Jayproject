# üìñ Noname
Goethe-Universit√§t Frankfurt am Main
Fachbereich 12 Institut f√ºr Informatik
Email: S6010479@stud.uni-frankfurt.de

## Title: Noname

Betreuer: Prof. Dr. Alexander Mehler, Dr. Andy L√ºcking, Dr. Alexander Henlein

###### Envisionhgdetector: https://envisionbox.org/embedded_UsingEnvisionHGdetector_package.html \
###### Dataset: TTLab Goethe-Universit√§t, University of Edinburgh, Centre for Language Evolution link: https://datashare.ed.ac.uk/handle/10283/3191 IFADV link: https://www.fon.hum.uva.nl/IFA-SpokenLanguageCorpora/IFADVcorpus/


Github: https://github.com/WimPouw/envisionhgdetector

Pythonlibrary: https://pypi.org/project/envisionhgdetector/ 


### Schritt:
1. Mit einem Tool f√ºr Bin√§re Klassifikation erkennen Gesten bzw. BIO-Label oder Gesten, Non-Gesten
2. Datensatz: R-Daten aus Va.Si.Li-Lab verwendet werden. Dazu geh√∂ren die Multiperspektiven-Videos 
3. Tool ausw√§hlen : Envisionhgdetector (Empfehlung von Dr. Henlein)
4. Ausf√ºhren den Envisionhgdetector mit Datensatz, ob er Gesten gut erkennt.
5. noch offen
