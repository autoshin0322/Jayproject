# Noname
Goethe-Universität Frankfurt am Main
Fachbereich 12 Institut für Informatik
Email: S6010479@stud.uni-frankfurt.de

Title: Noname

Betreuer: Prof. Dr. Alexander Mehler, Dr. Andy Lücking, Dr. Alexander Henlein

Envisionhgdetector: https://envisionbox.org/embedded_UsingEnvisionHGdetector_package.html, Dataset: TTLab Goethe-Universität, University of Edinburgh, Centre for Language Evolution link: https://datashare.ed.ac.uk/handle/10283/3191 IFADV link: https://www.fon.hum.uva.nl/IFA-SpokenLanguageCorpora/IFADVcorpus/


Github: https://github.com/WimPouw/envisionhgdetector

Pythonlibrary: https://pypi.org/project/envisionhgdetector/ 


Schritt:
1. Mit einem Tool für Binäre Klassifikation erkennen Gesten bzw. BIO-Label oder Gesten, Non-Gesten
2. Datensatz: R-Daten aus Va.Si.Li-Lab verwendet werden. Dazu gehören die Multiperspektiven-Videos 
3. Tool auswählen : Envisionhgdetector (Empfehlung von Dr. Henlein)
4. Ausführen den Envisionhgdetector mit Datensatz, ob er Gesten gut erkennt.
5. noch offen
