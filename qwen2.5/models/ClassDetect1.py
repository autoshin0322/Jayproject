import os
import csv
import torch
from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor
from qwen_vl_utils import process_vision_info

torch.cuda.empty_cache()
torch.cuda.ipc_collect()

MODEL_NAME = "Qwen/Qwen2.5-VL-7B-Instruct"
device = "cuda:0" if torch.cuda.is_available() else "cpu"

model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
    MODEL_NAME, torch_dtype="auto", device_map="cuda:0"
)
processor = AutoProcessor.from_pretrained(MODEL_NAME)

INPUT_DIR = "video42"
OUTPUT_CSV = "Video42Output.csv"

# CSV í—¤ë” ìƒì„±
with open(OUTPUT_CSV, mode="w", newline="", encoding="utf-8") as f:
    writer = csv.writer(f)
    writer.writerow(["index", "filename", "label"])

# ì˜ìƒ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
video_files = [f for f in sorted(os.listdir(INPUT_DIR)) if f.lower().endswith(".mp4")]

for idx, file_name in enumerate(video_files, start=1):
    video_path = os.path.join(INPUT_DIR, file_name)
    print(f"ğŸ¥ Processing ({idx}/{len(video_files)}): {file_name}")

    messages = [
        {
            "role": "user",
            "content": [
                {
                    "type": "video",
                    "video": video_path,
                    "max_pixels": 360 * 420,
                    "fps": 32.0,
                },
                {
                    "type": "text",
                    "text": (
                        "You are an expert in hand gesture recognition and classification based on visual input. "
                        "Analyze the given video and classify the primary hand gesture into one of the following eight categories: "
                        "representing, molding, indexing, drawing, other, beat, emblematic, or acting. "
                        "Output only the classification label without explanation."
                    ),
                },
            ],
        }
    ]

    # ì…ë ¥ ì¤€ë¹„
    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    image_inputs, video_inputs = process_vision_info(messages)
    inputs = processor(
        text=[text],
        images=image_inputs,
        videos=video_inputs,
        padding=True,
        return_tensors="pt",
    ).to(device)

    # ëª¨ë¸ ì‹¤í–‰
    with torch.no_grad():
        generated_ids = model.generate(**inputs, max_new_tokens=128)

    generated_ids_trimmed = [
        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
    ]
    output_text = processor.batch_decode(
        generated_ids_trimmed,
        skip_special_tokens=True,
        clean_up_tokenization_spaces=False,
    )[0].strip()

    print(f"ğŸ§  Output: {output_text}")

    # CSV ì €ì¥ (index í¬í•¨)
    with open(OUTPUT_CSV, mode="a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow([idx, file_name, output_text])

print("\nâœ… ëª¨ë“  ì˜ìƒ ì²˜ë¦¬ ì™„ë£Œ!")
print(f"ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {OUTPUT_CSV}")
