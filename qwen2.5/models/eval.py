import pandas as pd
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score

# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
true_df = pd.read_csv("clips.csv")
pred_df = pd.read_csv("results_classification(prompting).csv")

# index ê¸°ì¤€ìœ¼ë¡œ merge
merged_df = pd.merge(true_df, pred_df, on="index", suffixes=('_true', '_pred'))

# ë ˆì´ë¸” ì¶”ì¶œ
y_true = merged_df["label_true"]
y_pred = merged_df["label_pred"]

# ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ â†’ average='macro' ì‚¬ìš©
precision = precision_score(y_true, y_pred, average='macro')
recall = recall_score(y_true, y_pred, average='macro')
f1 = f1_score(y_true, y_pred, average='macro')
accuracy = accuracy_score(y_true, y_pred)

print("ğŸ“Š Evaluation Metrics:")
print(f"Precision: {precision:.4f}")
print(f"Recall:    {recall:.4f}")
print(f"F1-score:  {f1:.4f}")
print(f"Accuracy:  {accuracy:.4f}")
